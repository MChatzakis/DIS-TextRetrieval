{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ðŸŽ‰ A Text Retrieval Approach Using BM25 with BERT ðŸŽ‰\n","### TeamMGL: Manos Chatzakis, Hind El-Bouchrifi, Lluka Stojollari \n","\n","emmanouil.chatzakis@epfl.ch, hind.elbouchrifi@epfl.ch, lluka.stojollari@epfl.ch\n","\n","Distributed Information Systems, EPFL, Text Retrieval project, October 2023\n"]},{"cell_type":"markdown","metadata":{},"source":["## Contents:\n","This notebook contains the following stuff:\n","- Imports and Libraries:\n","    All the imports and libraries you need to run this notebook\n","- Utility Functions and Objects:\n","    All utility functions and class definitions needed to run this notebook\n","- Task 1:\n","    Code that generates the results for Text Retrieval task\n","- Task 2:\n","    Code that generates the results for Document Reranking task\n","- Submission File Generation\n","    Code that generates the submission CSV for Kaggle\n","\n","## Important Notes:\n","\n","- As this notebook uses BM25, which does not represents documents as vectors, it fits the model on the fly. Please note this and exclude this time from the total running time.\n","    - In order to help you with time counting, we placed a tqdm counter for Task 1 to indicate exactly how much time the text retrieval requires. The expected running time for Task 1 (as we noticed by running on Kaggle) is approximately 10-12 minutes. \n","    - Task 2 runs instantly\n","    - Although the model is fitted on the fly and it is not preloaded, fitting should not take more than a couple of minutes (4-5 minutes)\n","<br><br>\n","\n","- This notebook is meant to run in Kaggle environment. The needed files are placed under the working directory there. Those files are:\n","    - Full document corpus\n","    - Full queries file\n","    - Tokenized corpus\n","    - Query tests sets for Task 1 and Task 2\n","    - Corpus Embeddings for Task 1 and Task 2\n","<br><br>\n","\n","- This notebook contains only our final and best-scoring approach submitted in the Kaggle competition, and thus, it contains only the code needed for it. Our complete work, with all the models we implemented and used (e.g. Doc2Vec, TF-iDF, DSSM and more) as well as query expansion techniques are fully available in our GitHub repository, at: https://github.com/MChatzakis/DIS-TextRetrieval \n","\n","- You may need to install some libraries if you run this locally. "]},{"cell_type":"markdown","metadata":{},"source":["## Imports and Libraries"]},{"cell_type":"markdown","metadata":{},"source":["Sentence transformers are used for BERT, and should be installed in the notebook environment."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:43:52.121176Z","iopub.status.busy":"2023-10-21T21:43:52.120589Z","iopub.status.idle":"2023-10-21T21:44:11.491043Z","shell.execute_reply":"2023-10-21T21:44:11.489902Z","shell.execute_reply.started":"2023-10-21T21:43:52.121128Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentence-transformers in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (2.2.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.32.1)\n","Requirement already satisfied: tqdm in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n","Requirement already satisfied: torch>=1.6.0 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.0.1)\n","Requirement already satisfied: torchvision in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.15.2)\n","Requirement already satisfied: numpy in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.24.3)\n","Requirement already satisfied: scikit-learn in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\n","Requirement already satisfied: scipy in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.3)\n","Requirement already satisfied: nltk in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n","Requirement already satisfied: sentencepiece in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.17.3)\n","Requirement already satisfied: filelock in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n","Requirement already satisfied: fsspec in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n","Requirement already satisfied: requests in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n","Requirement already satisfied: packaging>=20.9 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n","Requirement already satisfied: sympy in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n","Requirement already satisfied: networkx in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n","Requirement already satisfied: click in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.0.4)\n","Requirement already satisfied: joblib in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /Users/manoschatzakis/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -U sentence-transformers"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:45:46.988603Z","iopub.status.busy":"2023-10-21T21:45:46.988168Z","iopub.status.idle":"2023-10-21T21:45:46.997251Z","shell.execute_reply":"2023-10-21T21:45:46.995793Z","shell.execute_reply.started":"2023-10-21T21:45:46.988570Z"},"trusted":true},"outputs":[],"source":["import nltk\n","import math\n","import json\n","import pickle\n","import os\n","import string\n","import heapq\n","import sentence_transformers\n","import time\n","import ast\n","import csv\n","\n","import pandas as pd\n","import numpy as np\n","\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from collections import Counter, defaultdict\n","from tqdm import tqdm\n","from numba import jit\n","from six import iteritems\n","from sentence_transformers import SentenceTransformer, util\n","\n","# Fix below\n","from six.moves import range\n","from collections.abc import Iterable"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:49:17.464854Z","iopub.status.busy":"2023-10-21T21:49:17.464398Z","iopub.status.idle":"2023-10-21T21:49:17.470751Z","shell.execute_reply":"2023-10-21T21:49:17.469454Z","shell.execute_reply.started":"2023-10-21T21:49:17.464821Z"},"trusted":true},"outputs":[],"source":["# Set the global data path variable\n","\n","# Path where corpus, queries and embeddings are stored\n","# DATA_PATH = \"/kaggle/input/dis-datasets/\" # Use for Kaggle\n","DATA_PATH = \"./data/dataset/\" # Use for local\n","\n","# Path where test queries for Task 1 and Task 2 are stored\n","# DIS_PATH = \"/kaggle/input/dis-project-1-text-retrieval/\" # Use for Kaggle\n","DIS_PATH = \"./data/\" # Use for local"]},{"cell_type":"markdown","metadata":{},"source":["## Useful Functions and Model Definitions"]},{"cell_type":"markdown","metadata":{},"source":["### BM25 Model Definition\n","\n","Here, we define the class of the bm25 Retrieval Model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:45:53.035275Z","iopub.status.busy":"2023-10-21T21:45:53.034896Z","iopub.status.idle":"2023-10-21T21:45:53.063343Z","shell.execute_reply":"2023-10-21T21:45:53.061689Z","shell.execute_reply.started":"2023-10-21T21:45:53.035245Z"},"trusted":true},"outputs":[],"source":["class bm25(object):\n","    \"\"\"bm25 class implements the BM25 ranking function.\"\"\"\n","\n","    def __init__(self, corpus_ids, corpus, k1=1.2, b=0.75, epsilon=0.75):\n","        \"\"\"The consutructor for bm25 class. Loads and saves the data used for fitting.\n","\n","        Args:\n","            corpus_ids (list): The ids of the documents in the corpus.\n","            corpus (list): The text corpus of the document collection.\n","            k1 (float, optional): k1 parameter of BM25. Defaults to 1.2.\n","            b (float, optional): b parameter of BM25. Defaults to 0.75.\n","            epsilon (float, optional): e parameter of BM25. Defaults to 0.75.\n","        \"\"\"\n","        self.k1 = k1\n","        self.b = b\n","        self.epsilon = epsilon\n","        self.corpus_size = 0\n","        self.avg_doc_length = 0\n","        self.doc_frequencies = []\n","        self.idf = {}\n","        self.doc_lengths = []\n","        self.corpus = corpus\n","        self.corpus_ids = corpus_ids\n","\n","    def fit(self):\n","        \"\"\"\n","        Fits the bm25 model.\n","        \"\"\"\n","        term_to_freq = defaultdict(int)\n","        total_length = 0\n","\n","        for document in self.corpus:\n","            self.corpus_size += 1\n","            doc_length = len(document)\n","            total_length += doc_length\n","            self.doc_lengths.append(doc_length)\n","\n","            frequencies = Counter(document)\n","            self.doc_frequencies.append(frequencies)\n","\n","            for term, freq in frequencies.items():\n","                term_to_freq[term] += 1\n","\n","        self.avg_doc_length = float(total_length) / self.corpus_size\n","        self.nd = term_to_freq\n","\n","        idf_sum = 0\n","        idf_len = 0\n","        negative_idfs = []\n","\n","        for word, freq in term_to_freq.items():\n","            idf = math.log((self.corpus_size + 1) / (freq))\n","            self.idf[word] = idf\n","            idf_len += 1\n","            idf_sum += idf\n","            if idf < 0:\n","                negative_idfs.append(word)\n","\n","        self.average_idf = idf_sum / idf_len\n","        eps = self.epsilon * self.average_idf\n","        self.idf.update({word: eps for word in negative_idfs})\n","\n","        document_score = {}\n","        for i, document in enumerate(self.corpus):\n","            doc_freqs = self.doc_frequencies[i]\n","            for word in document:\n","                if word not in doc_freqs:\n","                    continue\n","                score = self.idf[word] * (\n","                    doc_freqs[word]\n","                    * (self.k1 + 1)\n","                    / (\n","                        doc_freqs[word]\n","                        + self.k1\n","                        * (\n","                            1\n","                            - self.b\n","                            + self.b * self.doc_lengths[i] / self.avg_doc_length\n","                        )\n","                    )\n","                    + 1\n","                )\n","\n","                if word not in document_score:\n","                    document_score[word] = {i: round(score, 2)}\n","                else:\n","                    document_score[word].update({i: round(score, 2)})\n","        self.document_score = document_score\n","\n","    def compute_similarity(self, query, doc):\n","        \"\"\"Computers the similarity between the query and the document.\n","\n","        Args:\n","            query (list): Tokenized query\n","            doc (list): Tokenized document\n","\n","        Returns:\n","            float: The similarity score between the query and the document.\n","        \"\"\"\n","        score = 0\n","        doc_freqs = Counter(query)\n","        freq = 1\n","        default_idf = math.log(self.corpus_size + 1) - math.log(freq)\n","        for word in doc:\n","            if word not in doc_freqs:\n","                continue\n","            score += self.idf.get(word, default_idf) * (\n","                doc_freqs[word]\n","                * (self.k1 + 1)\n","                / (\n","                    doc_freqs[word]\n","                    + self.k1 * (1 - self.b + self.b * len(query) / self.avg_doc_length)\n","                )\n","                + 1\n","            )\n","        return score\n","\n","    def get_top_k_documents(self, document, k=1):\n","        \"\"\"Retrieve the top-k documents of a given document (query)\n","\n","        Args:\n","            document (list): the document query tokens\n","            k (int, optional): top-k documents to be retrieved. Defaults to 1.\n","\n","        Returns:\n","            list: a list of tuples (score, document_id, document) of the top-k documents\n","        \"\"\"\n","        score_overall = {}\n","        for word in document:\n","            if word not in self.document_score:\n","                continue\n","            for key, value in self.document_score[word].items():\n","                score_overall[key] = score_overall.get(key, 0) + value\n","\n","        k_keys_sorted = heapq.nlargest(k, score_overall, key=score_overall.get)\n","        return [\n","            (score_overall.get(item, None), self.corpus_ids[item], self.corpus[item])\n","            for item in k_keys_sorted\n","        ]"]},{"cell_type":"markdown","metadata":{},"source":["### Data Preprocessor\n","\n","Here we define the Preprocessor class. The preprocessor is used for Lowercasing, Punctuation Removal, Tokenizing, Stopword Removal and Stemming."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:46:00.136569Z","iopub.status.busy":"2023-10-21T21:46:00.136084Z","iopub.status.idle":"2023-10-21T21:46:00.466512Z","shell.execute_reply":"2023-10-21T21:46:00.465094Z","shell.execute_reply.started":"2023-10-21T21:46:00.136531Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/manoschatzakis/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/manoschatzakis/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /Users/manoschatzakis/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","\n","nltk.download(\"stopwords\")\n","nltk.download(\"punkt\")\n","nltk.download(\"wordnet\")  # Download WordNet data\n","\n","\n","class Preprocessor:\n","    \"\"\"\n","    Preprocessor class implements the preprocessing steps for the documents and queries.\n","    It performs the following steps:\n","        1. Lowercase\n","        2. Remove punctuation\n","        3. Tokenize\n","        4. Remove stopwords\n","        5. Stemming\n","\n","    Both for the documents and the queries.\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"Initialize the basic preprocessing structures.\"\"\"\n","        self.stemmer = PorterStemmer()\n","        self.stopwords = set(stopwords.words(\"english\"))\n","        self.punctuation = set(string.punctuation)\n","\n","    def preprocess(self, documents):\n","        \"\"\"Preprocess a collection of documents.\n","\n","        Args:\n","            documents (list or dict): list or dict{id: document} of documents to be preprocessed\n","\n","        Raises:\n","            TypeError: In case the documents are not a list or a dictionary\n","\n","        Returns:\n","            list or dict: The tokenized documents\n","        \"\"\"\n","        tokenized_docs = []\n","        if isinstance(documents, list):\n","            tokenized_docs = self.preprocess_document_list(documents)\n","        elif isinstance(documents, dict):\n","            tokenized_docs = self.preprocess_document_dict(documents)\n","        else:\n","            raise TypeError(\"Documents must be either a list or a dictionary\")\n","\n","        return tokenized_docs\n","\n","    def preprocess_query(self, query):\n","        \"\"\"Preprocess a query\n","\n","        Args:\n","            query (str): The query to be processed\n","\n","        Returns:\n","            list: Preprocessed query terms\n","        \"\"\"\n","        query = self.tolowercase(query)\n","        query = self.remove_punctuation(query)\n","\n","        query_tokens = self.tokenize(query)\n","        query_tokens = self.remove_stopwords(query_tokens)\n","\n","        query_tokens = self.stem(query_tokens)\n","\n","        return query_tokens\n","\n","    def preprocess_document_list(self, document_list):\n","        \"\"\"Preprocess a list of documents\n","\n","        Args:\n","            document_list (_type_): _description_\n","\n","        Returns:\n","            list: list of tokenized documents\n","        \"\"\"\n","        tokenized_docs = []\n","        for i in range(len(document_list)):\n","            tokenized_docs.append(self.preprocess_doc(document_list[i]))\n","        return tokenized_docs\n","\n","    def preprocess_document_dict(self, document_dict):\n","        \"\"\"Preprocess a dictionary of documents\n","\n","        Args:\n","            document_dict (dict): Dictionary of documents {id: document}\n","\n","        Returns:\n","            dict: Dictionary of tokenized documents {id: tokenized_document}\n","        \"\"\"\n","        tokenized_docs = {}\n","        for doc_id in document_dict.keys():\n","            document = document_dict[doc_id]\n","            tokenized_docs[doc_id] = self.preprocess_doc(document)\n","        return tokenized_docs\n","\n","    def preprocess_doc(self, document):\n","        \"\"\"Basic preprocessing pipeline for a document\n","\n","        Args:\n","            document (str): _description_\n","\n","        Returns:\n","            list: preprocess document tokens\n","        \"\"\"\n","        document = self.tolowercase(document)\n","        document = self.remove_punctuation(document)\n","\n","        document_tokens = self.tokenize(document)\n","        document_tokens = self.remove_stopwords(document_tokens)\n","        document_tokens = self.stem(document_tokens)\n","\n","        return document_tokens\n","\n","    def tolowercase(self, document):\n","        return document.lower()\n","\n","    def remove_punctuation(self, document):\n","        return \"\".join([char for char in document if char not in self.punctuation])\n","\n","    def tokenize(self, document):\n","        return word_tokenize(document)\n","\n","    def remove_stopwords(self, tokens):\n","        return [token for token in tokens if token not in self.stopwords]\n","\n","    def stem(self, tokens):\n","        return [self.stemmer.stem(token) for token in tokens]\n","\n","    def save_docs(self, docs, path):\n","        with open(path, \"w\") as jsonl_file:\n","            for docID in docs:\n","                doc_data = {\"_id\": str(docID), \"tokens\": docs[docID]}\n","                json_line = json.dumps(doc_data)\n","                jsonl_file.write(json_line + \"\\n\")\n","\n","    def load_docs(self, path):\n","        raw_queries = {}\n","        with open(path, \"r\") as file:\n","            for line in file:\n","                data = json.loads(line)\n","                raw_queries[data[\"_id\"]] = data[\"tokens\"]\n","\n","        return raw_queries"]},{"cell_type":"markdown","metadata":{},"source":["### Utility Functions\n","\n","Here, we define all the functions needed for various tasks of our pipeline."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:46:06.193171Z","iopub.status.busy":"2023-10-21T21:46:06.192747Z","iopub.status.idle":"2023-10-21T21:46:06.313015Z","shell.execute_reply":"2023-10-21T21:46:06.311799Z","shell.execute_reply.started":"2023-10-21T21:46:06.193140Z"},"trusted":true},"outputs":[],"source":["def cosine_similarity(vectors, query):\n","    \"\"\"\n","    Calculates cosine similarity between two vectors (or matrix and vector)\n","\n","    Args:\n","        vectors: X : Matrix X (np.array of vectors)\n","        query:   y : Vector y (np.array of query vector)\n","\n","    Returns:\n","        number: cosine similarity between X and y\n","    \"\"\"\n","    dot_products = np.dot(vectors, query)\n","\n","    norm_target = np.linalg.norm(query)\n","    norm_vectors = np.linalg.norm(vectors, axis=1)\n","\n","    # Calculate the cosine similarity between the target vector and all vectors in the array\n","    return dot_products / (norm_target * norm_vectors)\n","\n","\n","@jit(nopython=True)\n","def cosine_similarity_nb(u: np.ndarray, v: np.ndarray):\n","    \"\"\"An optimized version of cosine similarity.\n","\n","    Args:\n","        u (np.ndarray): u\n","        v (np.ndarray): v\n","\n","    Returns:\n","        float: The cosine similarity between u and v\n","    \"\"\"\n","    assert u.shape[0] == v.shape[0]\n","    uv = 0\n","    uu = 0\n","    vv = 0\n","    for i in range(u.shape[0]):\n","        uv += u[i] * v[i]\n","        uu += u[i] * u[i]\n","        vv += v[i] * v[i]\n","    cos_theta = 1\n","    if uu != 0 and vv != 0:\n","        cos_theta = uv / np.sqrt(uu * vv)\n","    return cos_theta\n","\n","\n","@jit(nopython=True)\n","def cosine_similarity_nb_matrix(X: np.ndarray, y: np.ndarray):\n","    \"\"\"An optimized version of cosine similarity, supporting matrices.\n","\n","    Args:\n","        X (np.ndarray): X\n","        y (np.ndarray): y\n","\n","    Returns:\n","        float: The cosine similarity for each vector X[i]*y\n","    \"\"\"\n","    cos_theta = np.zeros(X.shape[0])\n","    for i in range(X.shape[0]):\n","        cos_theta[i] = cosine_similarity_nb(X[i], y)\n","    return cos_theta\n","\n","\n","def load_jsonl_data(data_path: str, key_name: str, value_name: str):\n","    \"\"\"Load data from a JSONL file and return IDs, texts, and a dictionary mapping ids to text.\"\"\"\n","    ids, texts, dict_ = [], [], {}\n","\n","    with open(data_path, \"r\") as file:\n","        for line in file:\n","            data = json.loads(line)\n","            ids.append(data[key_name])\n","            texts.append(data[value_name])\n","            dict_[data[key_name]] = data[value_name]\n","\n","    return ids, texts, dict_"]},{"cell_type":"markdown","metadata":{},"source":["## Task 1: Text Retrieval\n","\n","In Task 1 we are given a set of approximately 7.5K queries and we retrieve the relevant documents over a corpus of 1.5M documents. \n","\n","Our retrieval method is based on the following method:\n","* Retrieve the top-N relevant documents of a query from the corpus, with N in {20,30,50,100}\n","* Rerank the retrieved top-N documents to get the final top-10 results using BERT"]},{"cell_type":"markdown","metadata":{},"source":["### Step 1: Load the corpus, queries and preprocessed corpus\n","\n","Everything is stored on Kaggle workspace, accessible from this notebook"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:46:42.305239Z","iopub.status.busy":"2023-10-21T21:46:42.304755Z","iopub.status.idle":"2023-10-21T21:47:29.668509Z","shell.execute_reply":"2023-10-21T21:47:29.667235Z","shell.execute_reply.started":"2023-10-21T21:46:42.305195Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of documents: 1471406\n","Number of queries: 509962\n"]}],"source":["# The preprocessed corpus is preprocessed using the Preprocessor class once, and we have stored the results locally.\n","RAW_CORPUS = f\"{DATA_PATH}corpus.jsonl\"\n","QUERIES = f\"{DATA_PATH}queries.jsonl\"\n","TOKENIZED_CORPUS = f\"{DATA_PATH}tokenized_corpus.jsonl\"\n","\n","# We specify the names of the fields in the JSONL files that we want to load.\n","document_ids, documents, docs_dict = load_jsonl_data(RAW_CORPUS, \"_id\", \"text\")\n","\n","query_ids, queries, queries_dict = load_jsonl_data(QUERIES, \"_id\", \"text\")\n","\n","tokenized_document_ids, tokenized_documents, tok_docs_dict = load_jsonl_data(\n","    TOKENIZED_CORPUS, \"_id\", \"tokens\"\n",")\n","\n","print(f\"Number of documents: {len(documents)}\")\n","print(f\"Number of queries: {len(queries)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Step 2: Load the precomputed corpus embeddings.\n","\n","We have precomputed the corpus embeddings in order to boost the performance during query answering"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:48:02.588452Z","iopub.status.busy":"2023-10-21T21:48:02.588016Z","iopub.status.idle":"2023-10-21T21:48:05.661972Z","shell.execute_reply":"2023-10-21T21:48:05.660814Z","shell.execute_reply.started":"2023-10-21T21:48:02.588410Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dimensions of BERT embeddings: 384\n"]}],"source":["# Load the object from the pickle file\n","CORPUS_EMB_PATH = f\"{DATA_PATH}embeddings_final.pkl\"\n","with open(CORPUS_EMB_PATH, \"rb\") as file:\n","    corpus_emb = pickle.load(file)\n","\n","EMBEDDING_DIM = list(corpus_emb.values())[0].shape[0]\n","print(f\"Dimensions of BERT embeddings: {EMBEDDING_DIM}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Step 3: Load the test query set for Task 1.\n","\n","The models are evaluated on Kaggle using a query set of approximately 7.5K queries for Task 1."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:49:28.212548Z","iopub.status.busy":"2023-10-21T21:49:28.212147Z","iopub.status.idle":"2023-10-21T21:49:28.235339Z","shell.execute_reply":"2023-10-21T21:49:28.233202Z","shell.execute_reply.started":"2023-10-21T21:49:28.212519Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of test queries for Task 1: 7437\n"]}],"source":["# Load the task 1 test queries\n","TEST_QUERIES_PATH_T1 = f\"{DIS_PATH}task1_test.tsv\"\n","t1_test_queries_df = pd.read_csv(TEST_QUERIES_PATH_T1, delimiter=\"\\t\")\n","\n","print(f\"Number of test queries for Task 1: {len(t1_test_queries_df)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Step 4: Fit the BM25 Model.\n","\n","Given the nature of the BM25 Model, we are unable to efficiently save the model and reuse it. Thus we fit it from scratch here. Locally fit takes just 1 minute! On Kaggle, it should need 3-4 minutes."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T21:49:35.807418Z","iopub.status.busy":"2023-10-21T21:49:35.807008Z","iopub.status.idle":"2023-10-21T21:53:15.990739Z","shell.execute_reply":"2023-10-21T21:53:15.989491Z","shell.execute_reply.started":"2023-10-21T21:49:35.807388Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BM25 fitted. Elapsed time: 59.982434034347534 seconds\n"]}],"source":["# Instanciate and fit the BM25 model and count time\n","st = time.time()\n","\n","model = bm25(tokenized_document_ids, tokenized_documents)\n","model.fit()\n","\n","et = time.time()\n","\n","print(f\"BM25 fitted. Elapsed time: {(et - st)} seconds\")"]},{"cell_type":"markdown","metadata":{},"source":["### Step 5: Retrieve the relevant documents!\n","\n","Now is the time to start retrieving the relevant documents for each one of the given queries! To do this, we split the computations into two parts for each query:\n","    a. Use BM25 to retrieve the top-n relevant documents for each query\n","    b. Use BERT Sentence Embeddings to rerank the retrieved set and obtain the top-10 documents for recall@10!"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["7437it [04:17, 28.92it/s]"]},{"name":"stdout","output_type":"stream","text":["Task 1 Done!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Select top N documents to retrieve per query\n","TOP_N = 100\n","\n","# Instanciate the preprocessor\n","preprocessor = Preprocessor()\n","\n","# Iterate over the queries and keep the IDs of the top 100 documents\n","top_N = []\n","\n","# Instanciate the SentenceTransformer model\n","st_bert = SentenceTransformer(\"all-MiniLM-L12-v2\")\n","\n","# List to store the results (we need them at the end to generate the submission file)\n","data = []\n","\n","# Set the number of documents to retrieve per query (Top-10 for Recall@10)\n","k = 10\n","\n","for idx, row in tqdm(t1_test_queries_df.iterrows()):\n","    #\n","    # Part 1: Retrieve the top-N relevant documents using BM25\n","    #\n","\n","    # Load query data\n","    id = row[\"id\"]\n","    query_id = row[\"query-id\"]\n","    query = queries_dict[str(query_id)]\n","\n","    # Preprocess the query and generate its terms\n","    tokenized_query = preprocessor.preprocess_query(query)\n","\n","    # Get the resulting documents. The format is: (score, document_id, document_terms)\n","    result = model.get_top_k_documents(tokenized_query, k=TOP_N)\n","\n","    #\n","    # Part 2: Rerank and select top-10 using BERT\n","    #\n","\n","    # Get the embeddings of the query\n","    query_embedding = st_bert.encode(query, show_progress_bar=False)\n","\n","    # Calculate the cosine similarity between the query embeddings and each document embedding\n","    cos_similarities = []\n","    index_to_docID = {}\n","    for i, r in enumerate(result):\n","        c_id = int(r[1])\n","        index_to_docID[i] = c_id\n","        cos_similarities.append(\n","            cosine_similarity_nb(corpus_emb[c_id], query_embedding)\n","        )\n","\n","    # Sometimes, BM25 might not retrieve enough documents, so we need to check\n","    curr_k = k\n","    if len(cos_similarities) < k:\n","        curr_k = len(cos_similarities)\n","\n","    # Get the indices of the top 'topn' most similar documents\n","    top_indices = np.argpartition(cos_similarities, -curr_k)[-curr_k:]\n","\n","    # Getdocument indices of the top documents\n","    top_k_docIDs = [index_to_docID[index] for index in top_indices]\n","\n","    # Append the data to the list\n","    data.append((idx, top_k_docIDs, -1))\n","\n","\n","print(\"Task 1 Done!\")"]},{"cell_type":"markdown","metadata":{},"source":["### That was it for Task 1! We kept the results in the \"data\" list, in order to generate the submission file in the end! âœ…"]},{"cell_type":"markdown","metadata":{},"source":["## Task 2: Document Re-ranking\n","\n","For the document reranking task, we use BERT embeddings to recalculate the score of the given relevant documents."]},{"cell_type":"markdown","metadata":{},"source":["### Step 1: Load the Task 2 test queries"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T22:20:53.283425Z","iopub.status.busy":"2023-10-21T22:20:53.282973Z","iopub.status.idle":"2023-10-21T22:20:53.314660Z","shell.execute_reply":"2023-10-21T22:20:53.313487Z","shell.execute_reply.started":"2023-10-21T22:20:53.283390Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of test queries for Task 2: 33\n"]}],"source":["T2_TEST_QUERIES_PATH = f\"{DIS_PATH}task2_test.tsv\"\n","t2_test_queries_df = pd.read_csv(T2_TEST_QUERIES_PATH, delimiter=\"\\t\")\n","\n","print(f\"Number of test queries for Task 2: {len(t2_test_queries_df)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Step 2: Load the embeddings corresponding to Task 2"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T22:21:18.112177Z","iopub.status.busy":"2023-10-21T22:21:18.111765Z","iopub.status.idle":"2023-10-21T22:21:18.480266Z","shell.execute_reply":"2023-10-21T22:21:18.479242Z","shell.execute_reply.started":"2023-10-21T22:21:18.112148Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dimension of BERT embeddings: 384\n"]}],"source":["# Load the Task 2 embeddings from the precomputed pickle file\n","CORPUS_EMB_PATH = f\"{DATA_PATH}embeddings_task2.pkl\"\n","with open(CORPUS_EMB_PATH, \"rb\") as file:\n","    corpus_emb_t2 = pickle.load(file)\n","\n","EMBEDDING_DIM = list(corpus_emb_t2.values())[0].shape[0]\n","print(f\"Dimension of BERT embeddings: {EMBEDDING_DIM}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Step 3: Rerank the given documents using BERT embeddings"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T22:21:21.618496Z","iopub.status.busy":"2023-10-21T22:21:21.618066Z","iopub.status.idle":"2023-10-21T22:21:23.721592Z","shell.execute_reply":"2023-10-21T22:21:23.720260Z","shell.execute_reply.started":"2023-10-21T22:21:21.618462Z"},"trusted":true},"outputs":[],"source":["# In order to not lose time, we resuse the SentenceTransformer model from Task 1\n","# st_bert = SentenceTransformer(\"all-MiniLM-L12-v2\")\n","\n","# For easiness, we reuse the data list from Task 1\n","# data = []\n","\n","# This task is relatively fast\n","for _, row in t2_test_queries_df.iterrows():\n","    # Get the query data\n","    id = row[\"id\"]\n","    query_id = row[\"query-id\"]\n","    query = queries_dict[str(query_id)]\n","\n","    # Infer the embedding vector for this query (this is performed at runtime, on the fly)\n","    query_embedding = st_bert.encode(query, show_progress_bar=False)\n","\n","    # Get the corpus IDs for this query (ast is used to convert the string to a list)\n","    corpus_ids = ast.literal_eval(row[\"corpus-id\"])\n","\n","    # Generate the scores for each one of the retrieved documents\n","    scores = []\n","    for corpus_id in corpus_ids:\n","        doc_emb = corpus_emb_t2[corpus_id]\n","\n","        # Add 2 to the cosine similarity score to make it positive (scaling up)\n","        score = cosine_similarity_nb(doc_emb, query_embedding) + 2\n","        scores.append(score)\n","\n","    # Reusing the data list from Task 1\n","    data.append((id, -1, scores))"]},{"cell_type":"markdown","metadata":{},"source":["## Submission File Generation\n","\n","Here, we generate the final submission file for both tasks. The file is saved in Kaggle workspace."]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T22:21:28.224670Z","iopub.status.busy":"2023-10-21T22:21:28.224255Z","iopub.status.idle":"2023-10-21T22:21:28.308176Z","shell.execute_reply":"2023-10-21T22:21:28.306684Z","shell.execute_reply.started":"2023-10-21T22:21:28.224637Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CSV file 'output.csv' has been created.\n"]}],"source":["# Save the results stored in data list to a CSV file\n","csv_file = \"output.csv\"\n","\n","with open(csv_file, mode=\"w\", newline=\"\") as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"id\", \"corpus-id\", \"score\"])\n","    writer.writerows(data) # Data holds the results from Task 1 and Task 2\n","\n","print(f\"CSV file '{csv_file}' has been created.\")"]},{"cell_type":"markdown","metadata":{},"source":["## The End! ðŸŽ‰\n","\n","If everything went fine, the query answering phase to generate the CSV file will score approximately 75% on Kaggle competition. Locally (using MacOS with m1-pro) we are able to generate the csv within 8 minutes. In Kaggle, it takes a bit more, approximately 10-12 minutes. ðŸ‘©â€ðŸ’»"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
