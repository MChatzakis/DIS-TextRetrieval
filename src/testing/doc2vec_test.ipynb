{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from models.doc2vec_model import Doc2VecModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus: 1471406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [27:49<00:00, 83.49s/it]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/dataset/corpus.jsonl\"\n",
    "max_docs = -1\n",
    "docs = {}\n",
    "with open(data_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        docs[data[\"_id\"]] = data[\"text\"]\n",
    "\n",
    "        if max_docs > 0 and len(docs) == max_docs:\n",
    "            break\n",
    "\n",
    "print(\"Number of documents in corpus: {}\".format(len(docs)))\n",
    "\n",
    "vector_size = 20\n",
    "window = 10\n",
    "min_count = 60\n",
    "workers = 16\n",
    "epochs = 20\n",
    "d2v = Doc2VecModel(\n",
    "    docs,\n",
    "    vector_size=vector_size,\n",
    "    window=window,\n",
    "    min_count=min_count,\n",
    "    workers=workers,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "d2v.fit()\n",
    "\n",
    "d2v.save(\n",
    "    f\"../../models/doc2vec.docs{len(d2v.model.dv)}.vs{vector_size}.win{window}.min{min_count}.ep{epochs}.model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data_path = \"../../data/dataset/queries.jsonl\"\n",
    "raw_queries = {}\n",
    "with open(query_data_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        docs[data[\"_id\"]] = data[\"text\"]\n",
    "\n",
    "query_ids_df = pd.read_csv(\"../../data/task1_train.tsv\")\n",
    "queries = {}\n",
    "for index, row in query_ids_df.iterrows():\n",
    "    query_id = row[\"query-id\"]\n",
    "\n",
    "    query_answer_id = row[\"corpus-id\"]\n",
    "    query_answer_score = row[\"score\"]\n",
    "\n",
    "    query_text = raw_queries[query_id]\n",
    "\n",
    "    queries[query_id] = {\n",
    "        \"text\": query_text,\n",
    "        \"answer_ids\": [(query_answer_id, query_answer_score)],\n",
    "    }\n",
    "\n",
    "\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "for id in queries.keys():\n",
    "    d2v_query_answers = d2v.find_similar(queries[id][\"text\"], TOP_K)\n",
    "    queries[id][\"d2v_answer_ids\"] = d2v_query_answers\n",
    "    \n",
    "    queries[id][\"precision@10\"] = 0\n",
    "    queries[id][\"recall@10\"] = 0\n",
    "\n",
    "queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
