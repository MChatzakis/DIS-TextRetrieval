{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functions and usage of Doc2Vec wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import random\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from models.doc2vec_model import Doc2VecModel, CompareBuildinAndCustomMostSimilar\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import IR_utils\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/dataset/corpus.jsonl\"\n",
    "max_docs = -1\n",
    "docs = {}\n",
    "with open(data_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        docs[data[\"_id\"]] = data[\"text\"]\n",
    "\n",
    "        if max_docs > 0 and len(docs) == max_docs:\n",
    "            break\n",
    "\n",
    "print(\"Number of documents in corpus: {}\".format(len(docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Todo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train or Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select to train or load a doc2vec model\n",
    "\n",
    "vector_size = 30\n",
    "window = 10\n",
    "min_count = 50\n",
    "workers = 16\n",
    "epochs = 100\n",
    "\n",
    "train_model = False\n",
    "if train_model:\n",
    "    d2v = Doc2VecModel.create_model(\n",
    "        documents=docs,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=workers,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "\n",
    "    d2v.fit(progress_bar=False)\n",
    "\n",
    "    d2v.save(\n",
    "        f\"../../models/doc2vec.docs{len(d2v.model.dv)}.vs{vector_size}.win{window}.min{min_count}.ep{epochs}.model\"\n",
    "    )\n",
    "else:\n",
    "    num_docs = len(docs)\n",
    "    \n",
    "    path = f\"../../models/doc2vec.docs{num_docs}.vs{vector_size}.win{window}.min{min_count}.ep{epochs}.model\"\n",
    "    \n",
    "    d2v = Doc2VecModel.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the query data\n",
    "query_data_path = \"../../data/dataset/queries.jsonl\"\n",
    "raw_queries = {}\n",
    "with open(query_data_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        raw_queries[int(data[\"_id\"])] = data[\"text\"]\n",
    "\n",
    "print(\"Number of queries: {}\".format(len(raw_queries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids_df = pd.read_csv(\"../../data/task1_train.tsv\", delimiter=\"\\t\")\n",
    "grouped_queries = query_ids_df.groupby(\"query-id\")\n",
    "\n",
    "queries = {}\n",
    "for query_id, group in grouped_queries:\n",
    "    relevant_doc_ids = group[\"corpus-id\"].tolist()\n",
    "    scores = group[\"score\"].tolist()\n",
    "\n",
    "    query_text = raw_queries[query_id]\n",
    "\n",
    "    queries[query_id] = {\n",
    "        \"text\": query_text,\n",
    "        \"relevant_doc_ids\": relevant_doc_ids,\n",
    "        \"relevant_doc_scores\": scores,\n",
    "    }\n",
    "\n",
    "print(\"Number of queries: {}\".format(len(queries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "query_ids_sample = random.sample(list(queries.keys()),10)\n",
    "query_ids = list(queries.keys())\n",
    "\n",
    "for query_id in tqdm(query_ids):\n",
    "    d2v_query_answers = d2v.find_similar(queries[query_id][\"text\"], TOP_K)\n",
    "    \n",
    "    retrieved_doc_ids = [id for id, score in d2v_query_answers]\n",
    "    retrieved_doc_scores = [score for id, score in d2v_query_answers]\n",
    "\n",
    "    queries[query_id][\"retrieved_doc_ids\"] = retrieved_doc_ids\n",
    "    queries[query_id][\"retrieved_doc_scores\"] = retrieved_doc_scores\n",
    "\n",
    "    queries[query_id][\"precision@10\"] = IR_utils.precision_K(\n",
    "        retrieved_docs=retrieved_doc_ids,\n",
    "        relevant_docs=queries[query_id][\"relevant_doc_ids\"],\n",
    "        K=10,\n",
    "    )\n",
    "\n",
    "    queries[query_id][\"recall@10\"] = IR_utils.recall_K(\n",
    "        retrieved_docs=retrieved_doc_ids,\n",
    "        relevant_docs=queries[query_id][\"relevant_doc_ids\"],\n",
    "        K=10,\n",
    "    )\n",
    "    \n",
    "    #d2v_query_answers_buildin = d2v.find_similar(queries[query_id][\"text\"], TOP_K, True)\n",
    "    #d2v_query_answers_buildin_ids = [x[0] for x in d2v_query_answers_buildin]\n",
    "    #print(d2v_query_answers_buildin_ids)\n",
    "    #print(retrieved_doc_ids)\n",
    "    #print()\n",
    "        \n",
    "    #if queries[query_id][\"precision@10\"] > 0.0:\n",
    "    #    print(queries[query_id][\"precision@10\"], queries[query_id][\"recall@10\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
