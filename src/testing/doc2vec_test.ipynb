{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functions and usage of Doc2Vec wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import random\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from models.doc2vec_model import Doc2VecModel, CompareBuildinAndCustomMostSimilar\n",
    "from tqdm import tqdm\n",
    "from preprocessors.preprocessor import Preprocessor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import IR_utils\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus: 1471406\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/dataset/corpus.jsonl\"\n",
    "max_docs = -1\n",
    "docs = {}\n",
    "with open(data_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        docs[data[\"_id\"]] = data[\"text\"]\n",
    "\n",
    "        if max_docs > 0 and len(docs) == max_docs:\n",
    "            break\n",
    "\n",
    "print(\"Number of documents in corpus: {}\".format(len(docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1471406/1471406 [08:37<00:00, 2842.12it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor()\n",
    "tokenized_docs = preprocessor.preprocess(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train or Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select to train or load a doc2vec model\n",
    "\n",
    "vector_size = 30\n",
    "window = 10\n",
    "min_count = 60\n",
    "workers = 16\n",
    "epochs = 150\n",
    "\n",
    "train_model = False\n",
    "if train_model:\n",
    "    d2v = Doc2VecModel.create_model(\n",
    "        documents=tokenized_docs,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=workers,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "\n",
    "    d2v.fit(progress_bar=False)\n",
    "\n",
    "    d2v.save(\n",
    "        f\"../../models/doc2vec.docs{len(d2v.model.dv)}.vs{vector_size}.win{window}.min{min_count}.ep{epochs}.model\"\n",
    "    )\n",
    "else:\n",
    "    num_docs = len(docs)\n",
    "    \n",
    "    path = f\"../../models/doc2vec.docs{num_docs}.vs{vector_size}.win{window}.min{min_count}.ep{epochs}.model\"\n",
    "    \n",
    "    d2v = Doc2VecModel.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries: 509962\n"
     ]
    }
   ],
   "source": [
    "# Load the query data\n",
    "query_data_path = \"../../data/dataset/queries.jsonl\"\n",
    "raw_queries = {}\n",
    "with open(query_data_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        raw_queries[int(data[\"_id\"])] = data[\"text\"]\n",
    "\n",
    "print(\"Number of queries: {}\".format(len(raw_queries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries: 502939\n"
     ]
    }
   ],
   "source": [
    "query_ids_df = pd.read_csv(\"../../data/task1_train.tsv\", delimiter=\"\\t\")\n",
    "grouped_queries = query_ids_df.groupby(\"query-id\")\n",
    "\n",
    "queries = {}\n",
    "for query_id, group in grouped_queries:\n",
    "    relevant_doc_ids = group[\"corpus-id\"].tolist()\n",
    "    scores = group[\"score\"].tolist()\n",
    "\n",
    "    query_text = raw_queries[query_id]\n",
    "\n",
    "    queries[query_id] = {\n",
    "        \"text\": query_text,\n",
    "        \"relevant_doc_ids\": relevant_doc_ids,\n",
    "        \"relevant_doc_scores\": scores,\n",
    "    }\n",
    "\n",
    "print(\"Number of queries: {}\".format(len(queries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 6451/502939 [05:55<7:35:46, 18.16it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/manoschatzakis/Documents/GitHub/DIS-TextRetrieval/src/testing/doc2vec_test.ipynb Cell 13\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manoschatzakis/Documents/GitHub/DIS-TextRetrieval/src/testing/doc2vec_test.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m query_ids \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(queries\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manoschatzakis/Documents/GitHub/DIS-TextRetrieval/src/testing/doc2vec_test.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m query_id \u001b[39min\u001b[39;00m tqdm(query_ids):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manoschatzakis/Documents/GitHub/DIS-TextRetrieval/src/testing/doc2vec_test.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     d2v_query_answers \u001b[39m=\u001b[39m d2v\u001b[39m.\u001b[39mfind_similar(queries[query_id][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m], TOP_K)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manoschatzakis/Documents/GitHub/DIS-TextRetrieval/src/testing/doc2vec_test.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     retrieved_doc_ids \u001b[39m=\u001b[39m [\u001b[39mid\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, score \u001b[39min\u001b[39;00m d2v_query_answers]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manoschatzakis/Documents/GitHub/DIS-TextRetrieval/src/testing/doc2vec_test.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     retrieved_doc_scores \u001b[39m=\u001b[39m [score \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, score \u001b[39min\u001b[39;00m d2v_query_answers]\n",
      "File \u001b[0;32m~/Documents/GitHub/DIS-TextRetrieval/src/testing/../models/doc2vec_model.py:85\u001b[0m, in \u001b[0;36mDoc2VecModel.find_similar\u001b[0;34m(self, query, topk, use_buildin)\u001b[0m\n\u001b[1;32m     83\u001b[0m     similar_documents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdv\u001b[39m.\u001b[39mmost_similar(positive\u001b[39m=\u001b[39m[vector], topn\u001b[39m=\u001b[39mtopk)\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     similar_documents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmost_similar(vector, topn\u001b[39m=\u001b[39mtopk)\n\u001b[1;32m     87\u001b[0m similar_documents \u001b[39m=\u001b[39m [\n\u001b[1;32m     88\u001b[0m     (\u001b[39mint\u001b[39m(docID), similarity) \u001b[39mfor\u001b[39;00m docID, similarity \u001b[39min\u001b[39;00m similar_documents\n\u001b[1;32m     89\u001b[0m ]\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m similar_documents\n",
      "File \u001b[0;32m~/Documents/GitHub/DIS-TextRetrieval/src/testing/../models/doc2vec_model.py:99\u001b[0m, in \u001b[0;36mDoc2VecModel.most_similar\u001b[0;34m(self, query_vector, topn)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmost_similar\u001b[39m(\u001b[39mself\u001b[39m, query_vector, topn\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n\u001b[1;32m     97\u001b[0m     \u001b[39m# Calculate cosine similarity between the input doc_vector and all doc_vectors in the model\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m#similarities = np.dot(self.model.dv.get_normed_vectors(), query_vector)\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     similarities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcosine_similarity(query_vector)\n\u001b[1;32m    101\u001b[0m     \u001b[39m# Get the indices of the top 'topn' most similar documents\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     top_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margpartition(similarities, \u001b[39m-\u001b[39mtopn)[\u001b[39m-\u001b[39mtopn:]\n",
      "File \u001b[0;32m~/Documents/GitHub/DIS-TextRetrieval/src/testing/../models/doc2vec_model.py:117\u001b[0m, in \u001b[0;36mDoc2VecModel.cosine_similarity\u001b[0;34m(self, query_vector)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcosine_similarity\u001b[39m(\u001b[39mself\u001b[39m, query_vector):\n\u001b[0;32m--> 117\u001b[0m     dot_products \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdv\u001b[39m.\u001b[39mget_normed_vectors(), query_vector)\n\u001b[1;32m    119\u001b[0m     norm_target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(query_vector)\n\u001b[1;32m    120\u001b[0m     norm_vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalized_norms\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "query_ids_sample = random.sample(list(queries.keys()),10)\n",
    "query_ids = list(queries.keys())\n",
    "\n",
    "for query_id in tqdm(query_ids):\n",
    "    d2v_query_answers = d2v.find_similar(queries[query_id][\"text\"], TOP_K)\n",
    "    \n",
    "    retrieved_doc_ids = [id for id, score in d2v_query_answers]\n",
    "    retrieved_doc_scores = [score for id, score in d2v_query_answers]\n",
    "\n",
    "    queries[query_id][\"retrieved_doc_ids\"] = retrieved_doc_ids\n",
    "    queries[query_id][\"retrieved_doc_scores\"] = retrieved_doc_scores\n",
    "\n",
    "    queries[query_id][\"precision@10\"] = IR_utils.precision_K(\n",
    "        retrieved_docs=retrieved_doc_ids,\n",
    "        relevant_docs=queries[query_id][\"relevant_doc_ids\"],\n",
    "        K=10,\n",
    "    )\n",
    "\n",
    "    queries[query_id][\"recall@10\"] = IR_utils.recall_K(\n",
    "        retrieved_docs=retrieved_doc_ids,\n",
    "        relevant_docs=queries[query_id][\"relevant_doc_ids\"],\n",
    "        K=10,\n",
    "    )\n",
    "    \n",
    "    #d2v_query_answers_buildin = d2v.find_similar(queries[query_id][\"text\"], TOP_K, True)\n",
    "    #d2v_query_answers_buildin_ids = [x[0] for x in d2v_query_answers_buildin]\n",
    "    #print(d2v_query_answers_buildin_ids)\n",
    "    #print(retrieved_doc_ids)\n",
    "    #print()\n",
    "        \n",
    "    #if queries[query_id][\"precision@10\"] > 0.0:\n",
    "    #    print(queries[query_id][\"precision@10\"], queries[query_id][\"recall@10\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
