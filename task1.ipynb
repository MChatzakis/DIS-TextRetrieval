{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/hind/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def load_jsonl_data_dict(data_path: str):\n",
    "    raw_dict = {}\n",
    "    with open(data_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            raw_dict[data['_id']] = data['text']\n",
    "    return raw_dict\n",
    "\n",
    "def get_vocab(documents):\n",
    "    vocabulary = list(set([item for sublist in documents for item in sublist]))\n",
    "    vocabulary.sort()\n",
    "\n",
    "    return vocabulary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1471406\n",
      "Number of queries:   509962\n"
     ]
    }
   ],
   "source": [
    "raw_documents = load_jsonl_data_dict(\"data/dataset/corpus.jsonl\")\n",
    "print(\"Number of documents: {}\".format(len(raw_documents)))\n",
    "\n",
    "raw_queries = load_jsonl_data_dict(\"data/dataset/queries.jsonl\")\n",
    "print(\"Number of queries:   {}\".format(len(raw_queries)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[' ',\n '!',\n '#',\n '$',\n '%',\n '&',\n \"'\",\n '(',\n ')',\n '*',\n '+',\n ',',\n '-',\n '.',\n '/',\n '0',\n '1',\n '2',\n '3',\n '4',\n '5',\n '6',\n '7',\n '8',\n '9',\n ':',\n ';',\n '<',\n '=',\n '>',\n '?',\n '@',\n 'A',\n 'B',\n 'C',\n 'D',\n 'E',\n 'F',\n 'G',\n 'H',\n 'I',\n 'J',\n 'K',\n 'L',\n 'M',\n 'N',\n 'O',\n 'P',\n 'Q',\n 'R',\n 'S',\n 'T',\n 'U',\n 'V',\n 'W',\n 'X',\n 'Y',\n 'Z',\n '[',\n '\\\\',\n ']',\n '^',\n '_',\n '`',\n 'a',\n 'b',\n 'c',\n 'd',\n 'e',\n 'f',\n 'g',\n 'h',\n 'i',\n 'j',\n 'k',\n 'l',\n 'm',\n 'n',\n 'o',\n 'p',\n 'q',\n 'r',\n 's',\n 't',\n 'u',\n 'v',\n 'w',\n 'x',\n 'y',\n 'z',\n '{',\n '|',\n '}',\n '~',\n '\\xa0',\n '£',\n '§',\n '®',\n '°',\n '²',\n 'µ',\n 'Â',\n 'É',\n 'ß',\n 'á',\n 'ã',\n 'ä',\n 'å',\n 'ç',\n 'è',\n 'é',\n 'ê',\n 'ë',\n 'í',\n 'î',\n 'ñ',\n 'ó',\n 'ö',\n 'ø',\n 'ú',\n 'ü',\n 'ă',\n 'ō',\n 'β',\n 'ت',\n 'ع',\n 'م',\n 'ن',\n '\\u200b',\n '‘',\n '’',\n '“',\n '”',\n '•',\n '◦',\n '\\ufeff']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocab(list(raw_queries.values()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 1, stop_words = 'english')\n",
    "\n",
    "# Fit and transform the documents to compute TF-IDF scores\n",
    "tfidf_matrix = vectorizer.fit_transform(raw_documents.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Similarity Score = 0.4853\n",
      "Manhattan Project. 1  The Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.\n",
      "3607205\n",
      "\n",
      "Rank 2: Similarity Score = 0.4781\n",
      "The project was given its name due to the fact that at least 10 of the sites used for the research were located in Manhattan. Following is a timeline of the key events related to the development of the atomic bomb and the Manhattan Project. Manhattan Project Timeline\n",
      "7243450\n",
      "\n",
      "Rank 3: Similarity Score = 0.4629\n",
      "Manhattan Project. The Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.anhattan Project. The Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.\n",
      "2036644\n",
      "\n",
      "Rank 4: Similarity Score = 0.4557\n",
      "Manhattan Project. The Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.he Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.\n",
      "3870080\n",
      "\n",
      "Rank 5: Similarity Score = 0.4499\n",
      "The Manhattan Project was a research and development project that produced the first nuclear weapons during World War II.he Army component of the project was designated the Manhattan District; Manhattan gradually superseded the official codename, Development of Substitute Materials, for the entire project. Along the way, the project absorbed its earlier British counterpart, Tube Alloys.\n",
      "3870082\n",
      "\n",
      "Rank 6: Similarity Score = 0.4419\n",
      "The Manhattan Project was a research and development project that produced the first atomic bombs during World War II. Here's an answer: The Manhattan Project was a movie made about Peter Stuyvesant's quest to buy the island of Manhattan from Native Americans back in the 1600s. For a better answer, look below.\n",
      "2395246\n",
      "\n",
      "Rank 7: Similarity Score = 0.4334\n",
      "Learner's definition of IMMEDIATE. 1. a : happening or done without delay. This requires your immediate attention. The new restaurant was an immediate success. This crisis calls for immediate action. The response to the crisis was immediate.\n",
      "462457\n",
      "\n",
      "Rank 8: Similarity Score = 0.4191\n",
      "The Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.\n",
      "4138462\n",
      "\n",
      "Rank 9: Similarity Score = 0.4120\n",
      "The Manhattan Project -- Its Operations. Major operations for the Manhattan Engineer District (Manhattan Project) took place in remote site locations in the states of Tennessee, New Mexico, and Washington, with additional research being conducted in university laboratories at Chicago and Berkeley.\n",
      "5117689\n",
      "\n",
      "Rank 10: Similarity Score = 0.3978\n",
      "This article is about the atomic bomb project. For other uses, see Manhattan Project (disambiguation). The Manhattan Project was a research and development undertaking during World War II that produced the first nuclear weapons. It was led by the United States with the support of the United Kingdom and Canada.\n",
      "2148554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query = \")what was the immediate impact of the success of the manhattan project?\"\n",
    "\n",
    "# Vectorize the query using the same TF-IDF vectorizer\n",
    "query_vector = vectorizer.transform([query])\n",
    "query_vector.toarray()\n",
    "cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "document_indices_sorted_by_similarity = cosine_similarities[0].argsort()[::-1]\n",
    "\n",
    "# Get the corresponding similarity scores\n",
    "similarity_scores_sorted = cosine_similarities[0][document_indices_sorted_by_similarity]\n",
    "document_indices_sorted_by_similarity\n",
    "num_top_documents = 10\n",
    "\n",
    "# Retrieve the top N documents and their similarity scores\n",
    "top_documents = [list(raw_documents.values())[i] for i in document_indices_sorted_by_similarity[:num_top_documents]]\n",
    "top_documents_ids = [list(raw_documents.keys())[i] for i in document_indices_sorted_by_similarity[:num_top_documents]]\n",
    "\n",
    "top_similarity_scores = similarity_scores_sorted[:num_top_documents]\n",
    "\n",
    "# Present the results\n",
    "for i, (document, similarity, id_) in enumerate(zip(top_documents, top_similarity_scores, top_documents_ids), start=1):\n",
    "    print(f\"Rank {i}: Similarity Score = {similarity:.4f}\")\n",
    "    print(document)\n",
    "    print(id_)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query-id  corpus-id  score\n",
      "0   1185869          0      1\n",
      "1   1185868         16      1\n",
      "2    597651         49      1\n",
      "3    403613         60      1\n",
      "4   1183785        389      1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/task1_train.tsv', sep='\\t')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_df.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "[1185869,\n 1185868,\n 597651,\n 403613,\n 1183785,\n 312651,\n 80385,\n 645590,\n 645337,\n 186154,\n 457407,\n 441383,\n 683408,\n 1164799,\n 484187,\n 460668,\n 666321,\n 182487,\n 564233,\n 455279,\n 208108,\n 733739,\n 1164798,\n 402608,\n 443797,\n 662502,\n 1184679,\n 14562,\n 602162,\n 545059,\n 708236,\n 310130,\n 693161,\n 186617,\n 573027,\n 1173772,\n 541973,\n 273090,\n 441269,\n 642237,\n 503515,\n 637443,\n 1164796,\n 749988,\n 749988,\n 135841,\n 295446,\n 653051,\n 691147,\n 410621,\n 410621,\n 1164795,\n 598443,\n 596451,\n 651441,\n 452286,\n 308543,\n 202126,\n 114820,\n 501778,\n 531029,\n 651110,\n 594127,\n 1164794,\n 396032,\n 705580,\n 658203,\n 387734,\n 655102,\n 224712,\n 411732,\n 1164793,\n 605902,\n 581014,\n 559240,\n 608711,\n 535936,\n 130335,\n 147535,\n 1164792,\n 595576,\n 569308,\n 753706,\n 627871,\n 673608,\n 510071,\n 113839,\n 1164791,\n 460953,\n 685235,\n 650643,\n 1183784,\n 1164790,\n 96740,\n 26666,\n 490046,\n 485823,\n 635632,\n 534505,\n 498612,\n 85453,\n 493122,\n 512836,\n 605764,\n 748182,\n 725274,\n 401461,\n 499565,\n 641186,\n 468434,\n 31086,\n 480268,\n 742160,\n 305154,\n 1164787,\n 688661,\n 1173771,\n 535243,\n 535243,\n 477240,\n 321187,\n 755409,\n 553140,\n 88585,\n 88585,\n 88585,\n 416278,\n 652801,\n 448861,\n 609117,\n 508975,\n 686474,\n 1164784,\n 390443,\n 342332,\n 396120,\n 82631,\n 430171,\n 422799,\n 564701,\n 677722,\n 659630,\n 396846,\n 667478,\n 165324,\n 118,\n 531802,\n 457773,\n 1164782,\n 1164782,\n 1164782,\n 650692,\n 622007,\n 492528,\n 642101,\n 481431,\n 481431,\n 296072,\n 296072,\n 711452,\n 608452,\n 476121,\n 451572,\n 170935,\n 212020,\n 756195,\n 321944,\n 626785,\n 398567,\n 398567,\n 499488,\n 522059,\n 617436,\n 17008,\n 510363,\n 311755,\n 320624,\n 520990,\n 344949,\n 670628,\n 670628,\n 620254,\n 561453,\n 716682,\n 306728,\n 448235,\n 696473,\n 476888,\n 480096,\n 511086,\n 1164777,\n 1164777,\n 538223,\n 173769,\n 427099,\n 508811,\n 391495,\n 576864,\n 292137,\n 588376,\n 588376,\n 588376,\n 1164776,\n 1173770,\n 630360,\n 406188,\n 576138,\n 617804,\n 30619,\n 574110,\n 574702,\n 316639,\n 751529,\n 502248,\n 502248,\n 486399,\n 708195,\n 116736,\n 559956,\n 360382,\n 574325,\n 1164772,\n 515331,\n 418844,\n 290590,\n 726424,\n 1184764,\n 433744,\n 671399,\n 651938,\n 746395,\n 280775,\n 437723,\n 545859,\n 545859,\n 742685,\n 591348,\n 697504,\n 24388,\n 596155,\n 707182,\n 649051,\n 759231,\n 1183782,\n 468728,\n 453298,\n 460001,\n 502926,\n 661940,\n 661940,\n 242169,\n 675962,\n 575787,\n 459088,\n 1164764,\n 624575,\n 138829,\n 431504,\n 691516,\n 11653,\n 11653,\n 423287,\n 1173769,\n 1164761,\n 583734,\n 448621,\n 608955,\n 744373,\n 287532,\n 624752,\n 396288,\n 683242,\n 1164759,\n 189935,\n 189935,\n 189935,\n 690255,\n 593603,\n 445857,\n 193384,\n 656174,\n 395608,\n 1164758,\n 449132,\n 15252,\n 565659,\n 482806,\n 705802,\n 663380,\n 1174666,\n 252674,\n 541895,\n 441367,\n 512638,\n 616319,\n 308679,\n 500192,\n 5202,\n 610542,\n 465276,\n 639751,\n 747871,\n 741934,\n 413103,\n 593717,\n 592050,\n 685380,\n 71865,\n 684440,\n 138729,\n 634747,\n 575732,\n 612478,\n 426221,\n 674833,\n 215545,\n 600133,\n 1183781,\n 219912,\n 707196,\n 724592,\n 495625,\n 675176,\n 748701,\n 455980,\n 1164749,\n 641438,\n 684298,\n 644111,\n 754337,\n 330982,\n 452366,\n 711476,\n 661860,\n 478196,\n 592008,\n 165453,\n 443458,\n 695106,\n 474783,\n 1164746,\n 55048,\n 385458,\n 548479,\n 499812,\n 15408,\n 422167,\n 457348,\n 457348,\n 754130,\n 1164745,\n 117664,\n 753352,\n 435356,\n 445911,\n 476407,\n 121365,\n 412886,\n 412886,\n 510172,\n 1164744,\n 1164744,\n 523140,\n 13315,\n 657061,\n 603130,\n 589631,\n 589631,\n 81707,\n 81707,\n 81707,\n 730829,\n 1164743,\n 618583,\n 399731,\n 613644,\n 613644,\n 623325,\n 575269,\n 653151,\n 1164742,\n 735199,\n 18970,\n 557583,\n 728984,\n 403058,\n 572255,\n 735744,\n 447671,\n 49432,\n 610634,\n 636587,\n 79048,\n 601958,\n 213201,\n 684329,\n 289167,\n 289167,\n 1183780,\n 1164740,\n 411572,\n 395288,\n 45348,\n 592967,\n 386034,\n 438666,\n 407016,\n 614703,\n 504875,\n 504875,\n 6811,\n 1164739,\n 490998,\n 247230,\n 247230,\n 431784,\n 591492,\n 492479,\n 440856,\n 447830,\n 569593,\n 154289,\n 557644,\n 661106,\n 185266,\n 710271,\n 495054,\n 1173767,\n 1173767,\n 1173767,\n 1173767,\n 709018,\n 515427,\n 1164737,\n 574996,\n 221711,\n 261678,\n 709162,\n 612024,\n 1164736,\n 597443,\n 606851,\n 448166,\n 37504,\n 738470,\n 310290,\n 553949,\n 428555,\n 442860,\n 523281,\n 581306,\n 576539,\n 447937,\n 276450,\n 710991,\n 480298,\n 596897,\n 23937,\n 649867,\n 649867,\n 711556,\n 449147,\n 1164733,\n 484785,\n 385698,\n 699911,\n 134627,\n 624097,\n 543762,\n 470449,\n 508527,\n 495126,\n 458121,\n 741772,\n 414496,\n 520945,\n 587473,\n 101453,\n 718690,\n 563293,\n 511889,\n 483949,\n 469757,\n 532152,\n 121474,\n 403810,\n 735486,\n 514688,\n 216639,\n 634235,\n 577404,\n 228668,\n 686791,\n 699971,\n 445089,\n 729120,\n 1164725,\n 280515,\n 584878,\n 584878,\n 584878,\n 624360,\n 408938,\n 153580,\n 568535,\n 568535,\n 568535,\n 487682,\n 1164724,\n 612170,\n 124961,\n 374612,\n 618540,\n 430318,\n 620568,\n 1173766,\n 667985,\n 601987,\n 276042,\n 757003,\n 483746,\n 325993,\n 736493,\n 603520,\n 603520,\n 656030,\n 665144,\n 1164722,\n 416098,\n 634365,\n 70228,\n 546584,\n 1164721,\n 1164721,\n 1164721,\n 544357,\n 654573,\n 598046,\n 614234,\n 529320,\n 529320,\n 289051,\n 332622,\n 272115,\n 318209,\n 575693,\n 497067,\n 519307,\n 599617,\n 700838,\n 751663,\n 491271,\n 1164719,\n 642276,\n 427705,\n 612757,\n 713518,\n 643669,\n 677853,\n 449951,\n 599225,\n 644299,\n 339438,\n 711391,\n 613131,\n 1164717,\n 52216,\n 140670,\n 671768,\n 629699,\n 630158,\n 645588,\n 733774,\n 133098,\n 287144,\n 2500,\n 1183778,\n 93889,\n 93889,\n 163844,\n 112716,\n 642081,\n 614942,\n 702173,\n 741900,\n 399407,\n 602237,\n 587547,\n 393087,\n 614226,\n 385794,\n 654757,\n 627848,\n 684083,\n 735646,\n 488165,\n 1173765,\n 694128,\n 463892,\n 543110,\n 1164713,\n 107055,\n 650899,\n 736973,\n 369518,\n 685854,\n 396424,\n 396424,\n 1164712,\n 516558,\n 504412,\n 558936,\n 467090,\n 742414,\n 531189,\n 1164711,\n 433601,\n 443892,\n 526495,\n 526495,\n 526495,\n 489571,\n 634512,\n 435183,\n 681529,\n 413930,\n 499265,\n 687733,\n 1164709,\n 389184,\n 740464,\n 459067,\n 441889,\n 441889,\n 512345,\n 137796,\n 1164708,\n 1164708,\n 545663,\n 728967,\n 686980,\n 457962,\n 656232,\n 98709,\n 662874,\n 396955,\n 31928,\n 596601,\n 727631,\n 525651,\n 524839,\n 154864,\n 564795,\n 564795,\n 1164706,\n 669148,\n 184048,\n 400840,\n 721061,\n 582984,\n 758492,\n 458594,\n 184674,\n 729613,\n 24289,\n 1164705,\n 1164705,\n 746789,\n 581533,\n 396563,\n 655160,\n 393874,\n 434802,\n 1164704,\n 122232,\n 223385,\n 746880,\n 1173764,\n 688363,\n 251846,\n 416665,\n 520164,\n 428365,\n 1164703,\n 665391,\n 665391,\n 737115,\n 643162,\n 15116,\n 663605,\n 663605,\n 754126,\n 290872,\n 1164702,\n 102222,\n 735510,\n 469986,\n 613280,\n 449393,\n 599114,\n 1164701,\n 571673,\n 614202,\n 646727,\n 134744,\n 609486,\n 519297,\n 299873,\n 1164700,\n 560136,\n 744886,\n 532472,\n 47283,\n 452108,\n 452108,\n 570962,\n 74743,\n 442909,\n 586715,\n 533264,\n 404264,\n 457416,\n 457416,\n 396012,\n 123612,\n 452484,\n 753808,\n 646752,\n 463521,\n 349485,\n 209441,\n 502658,\n 134574,\n 582460,\n 573198,\n 399614,\n 512028,\n 509581,\n 724120,\n 189618,\n 548882,\n 419154,\n 584788,\n 584788,\n 262345,\n 543336,\n 638530,\n 1164695,\n 5048,\n 704144,\n 472484,\n 727428,\n 1164694,\n 490734,\n 733932,\n 753458,\n 723396,\n 723396,\n 627573,\n 279610,\n 302360,\n 151130,\n 151130,\n 151130,\n 746079,\n 470036,\n 564559,\n 573413,\n 1164692,\n 514870,\n 581208,\n 407412,\n 204038,\n 204038,\n 231633,\n 21452,\n 413786,\n 704275,\n 426690,\n 735907,\n 306274,\n 271809,\n 739506,\n 1164689,\n 1164689,\n 599730,\n 474932,\n 450662,\n 550740,\n 569982,\n 76118,\n 630528,\n 588585,\n 490535,\n 242206,\n 603316,\n 144366,\n 184150,\n 650883,\n 75480,\n 575981,\n 753821,\n 613974,\n 509867,\n 509867,\n 250372,\n 1164686,\n 1164686,\n 1164686,\n 1164686,\n 214743,\n 181093,\n 417336,\n 735878,\n 1164685,\n 400791,\n 181705,\n 412683,\n 645068,\n 470311,\n 719003,\n 218252,\n 550729,\n 1164684,\n 609542,\n 476796,\n 144059,\n 299131,\n 487595,\n 533133,\n 719805,\n 1164683,\n 626425,\n 626425,\n 584552,\n 1184678,\n 709635,\n 677776,\n 423912,\n 423912,\n 755239,\n 667780,\n 1164682,\n 278124,\n 760311,\n 95746,\n 95746,\n 95746,\n 412652,\n 720466,\n 699723,\n 1164680,\n 61922,\n 445336,\n 411178,\n 64719,\n 178738,\n 511462,\n 511462,\n 511462,\n 560526,\n 729517,\n 635977,\n 426703,\n 92682,\n 92682,\n 308455,\n 578221,\n 77087,\n 741380,\n 420442,\n 399388,\n 516030,\n 760671,\n 551947,\n 407784,\n 295557,\n 601980,\n 252470,\n 219871,\n 593451,\n 548647,\n 295878,\n 546073,\n 1164673,\n 651052,\n 151098,\n 705100,\n 707323,\n 500781,\n 603030,\n 1164672,\n 606333,\n 571330,\n 416509,\n 527888,\n 1183774,\n 1164671,\n 1164671,\n 436437,\n 639976,\n 469923,\n 516199,\n 227004,\n 670857,\n 651086,\n 441386,\n 678684,\n 87278,\n 147363,\n 147363,\n 197586,\n 581917,\n 466532,\n 115986,\n 1164669,\n 587773,\n 84285,\n 606868,\n 607886,\n 697001,\n 546075,\n 733482,\n 1164667,\n 330083,\n 736314,\n 639961,\n 290973,\n 645657,\n 400551,\n 530355,\n 530355,\n 530355,\n 711079,\n 634990,\n 456510,\n 1164666,\n 243321,\n 705423,\n 442662,\n 442662,\n 702662,\n 530301,\n 244107,\n 436036,\n 490937,\n 625624,\n 49498,\n 287540,\n 671661,\n 396072,\n 677572,\n 592475,\n 682758,\n 682758,\n 666453,\n 41844,\n 523181,\n 224956,\n 1164663,\n 529456,\n 613823,\n 410253,\n 757882,\n 144903,\n 1480,\n 623981,\n 385318,\n 719836,\n 695822,\n 474542,\n 232129,\n 1164661,\n 124727,\n 248762,\n 604830,\n 556017,\n 1183773,\n 1164660,\n 198783,\n 687387,\n 382445,\n 651899,\n 662261,\n 521321,\n 415237,\n 1164659,\n 449828,\n 544857,\n 615290,\n 436538,\n 728788,\n 1164658,\n 653717,\n 440476,\n 86935,\n 541311,\n 470424,\n 760246,\n 444313,\n ...]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_ids = list(train_df['query-id'])\n",
    "query_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def get_top_10(query, query_id):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    query_vector.toarray()\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "    document_indices_sorted_by_similarity = cosine_similarities[0].argsort()[::-1]\n",
    "\n",
    "    similarity_scores_sorted = cosine_similarities[0][document_indices_sorted_by_similarity]\n",
    "    document_indices_sorted_by_similarity\n",
    "    num_top_documents = 10\n",
    "\n",
    "    top_documents = [list(raw_documents.values())[i] for i in document_indices_sorted_by_similarity[:num_top_documents]]\n",
    "    top_documents_ids = [list(raw_documents.keys())[i] for i in document_indices_sorted_by_similarity[:num_top_documents]]\n",
    "\n",
    "    top_similarity_scores = similarity_scores_sorted[:num_top_documents]\n",
    "\n",
    "    return top_documents_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{1185869: ['3607205',\n  '7243450',\n  '2036644',\n  '3870080',\n  '3870082',\n  '2395246',\n  '462457',\n  '4138462',\n  '5117689',\n  '2148554'],\n 1185868: ['4204615',\n  '1641650',\n  '3020376',\n  '6821177',\n  '16',\n  '4219366',\n  '6900825',\n  '4285040',\n  '8339717',\n  '1525277'],\n 597651: ['217868',\n  '6398884',\n  '6836989',\n  '4334506',\n  '6770277',\n  '2172327',\n  '2617786',\n  '7653670',\n  '162760',\n  '6264745'],\n 403613: ['8161983',\n  '261443',\n  '3824713',\n  '1041491',\n  '1945651',\n  '3797201',\n  '1924201',\n  '6999540',\n  '6242980',\n  '8381473'],\n 1183785: ['389',\n  '8730384',\n  '7087848',\n  '7051451',\n  '7142224',\n  '7684506',\n  '3938573',\n  '2257752',\n  '8718244',\n  '246254'],\n 312651: ['4229988',\n  '6734984',\n  '1250194',\n  '4123611',\n  '1437908',\n  '610',\n  '2464811',\n  '7336587',\n  '2408004',\n  '2384542'],\n 80385: ['2494972',\n  '2867801',\n  '2161672',\n  '4233993',\n  '2161665',\n  '6310939',\n  '194251',\n  '3839570',\n  '7755089',\n  '2332611'],\n 645590: ['89161',\n  '3899722',\n  '944',\n  '3102734',\n  '5735683',\n  '6902383',\n  '8497431',\n  '5342371',\n  '734471',\n  '4870555'],\n 645337: ['826892',\n  '169073',\n  '8350281',\n  '4943567',\n  '826895',\n  '826888',\n  '8074716',\n  '3078638',\n  '8350280',\n  '826886'],\n 186154: ['5862502',\n  '6835058',\n  '6242059',\n  '1420231',\n  '392001',\n  '2302495',\n  '5599808',\n  '637520',\n  '8733946',\n  '5231446'],\n 457407: ['1233516',\n  '6421558',\n  '5543715',\n  '129065',\n  '2107809',\n  '7019276',\n  '2796160',\n  '8386099',\n  '6078911',\n  '2094266'],\n 441383: ['1389',\n  '3884881',\n  '6694981',\n  '20073',\n  '2213812',\n  '8609679',\n  '208011',\n  '2009826',\n  '418065',\n  '6249757'],\n 683408: ['816086',\n  '5602121',\n  '5865971',\n  '8623957',\n  '816082',\n  '5389169',\n  '1605',\n  '5602120',\n  '592104',\n  '5389177'],\n 1164799: ['7112465',\n  '5109011',\n  '789744',\n  '5505828',\n  '7870183',\n  '2186668',\n  '8726490',\n  '6297775',\n  '440089',\n  '1235040'],\n 484187: ['6813820',\n  '3596561',\n  '1822',\n  '2000369',\n  '4870647',\n  '1826',\n  '1329647',\n  '4793354',\n  '4207613',\n  '6793630'],\n 460668: ['7761110',\n  '1687237',\n  '4650509',\n  '8771217',\n  '1687236',\n  '2128001',\n  '5063573',\n  '750622',\n  '3921510',\n  '4328067'],\n 666321: ['8314196',\n  '2066333',\n  '6030612',\n  '859534',\n  '2155',\n  '1629306',\n  '1821244',\n  '4930043',\n  '8165890',\n  '993617'],\n 182487: ['4171994',\n  '5792901',\n  '511187',\n  '2643411',\n  '5042272',\n  '5042270',\n  '4136365',\n  '2996323',\n  '4661559',\n  '6273455'],\n 564233: ['4748277',\n  '6758225',\n  '2755037',\n  '5405929',\n  '7140495',\n  '7210924',\n  '828531',\n  '8445607',\n  '3585716',\n  '2949516'],\n 455279: ['5059516',\n  '4984645',\n  '8105434',\n  '952728',\n  '6975255',\n  '794650',\n  '5302364',\n  '648840',\n  '7257574',\n  '5788984']}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = {}\n",
    "for query_id in query_ids[:20]:\n",
    "    query = raw_queries[str(query_id)]\n",
    "    res[query_id] = get_top_10(query, query_id)\n",
    "\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from gensim.summarization.bm25 import BM25\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Tokenize the documents (you can use your own tokenization method)\n",
    "tokenized_documents = [doc.split() for doc in raw_documents.values()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Document 1403702, BM25 Score = 33.0991\n",
      "Rank 2: Document 981590, BM25 Score = 32.9258\n",
      "Rank 3: Document 989139, BM25 Score = 31.6476\n",
      "Rank 4: Document 504882, BM25 Score = 31.2029\n",
      "Rank 5: Document 1006512, BM25 Score = 30.5902\n",
      "Rank 6: Document 1101667, BM25 Score = 29.1159\n",
      "Rank 7: Document 573022, BM25 Score = 29.0387\n",
      "Rank 8: Document 307611, BM25 Score = 28.9447\n",
      "Rank 9: Document 1028360, BM25 Score = 28.2745\n",
      "Rank 10: Document 329684, BM25 Score = 28.1823\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25(tokenized_documents)\n",
    "query = raw_queries['597651']\n",
    "tokenized_query = query.split()\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "sorted_documents = sorted(enumerate(bm25_scores), key=lambda x: x[1], reverse=True)\n",
    "top_10_documents = sorted_documents[:10]\n",
    "\n",
    "for rank, (doc_idx, score) in enumerate(top_10_documents):\n",
    "    print(f\"Rank {rank + 1}: Document {doc_idx}, BM25 Score = {score:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Document 6398884, BM25 Score = 33.0991\n",
      "Rank 2: Document 5946033, BM25 Score = 32.9258\n",
      "Rank 3: Document 162760, BM25 Score = 31.6476\n",
      "Rank 4: Document 783336, BM25 Score = 31.2029\n",
      "Rank 5: Document 217868, BM25 Score = 30.5902\n",
      "Rank 6: Document 1794262, BM25 Score = 29.1159\n",
      "Rank 7: Document 266682, BM25 Score = 29.0387\n",
      "Rank 8: Document 6836989, BM25 Score = 28.9447\n",
      "Rank 9: Document 584377, BM25 Score = 28.2745\n",
      "Rank 10: Document 5717066, BM25 Score = 28.1823\n"
     ]
    }
   ],
   "source": [
    "for rank, (doc_idx, score) in enumerate(top_10_documents):\n",
    "    print(f\"Rank {rank + 1}: Document {list(raw_documents.keys())[doc_idx] }, BM25 Score = {score:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_recall_at_k(predict, gt, k):\n",
    "    correct_recall = set(predict[:k]).intersection(set(gt))\n",
    "    return len(correct_recall)/len(gt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/8l/38mw0fgd64x6gy7hbrcdfb1r0000gn/T/ipykernel_5346/2821772929.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Retrieval oracle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mtf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTfidfVectorizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manalyzer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'word'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mngram_range\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'english'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mfeatures\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_documents\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mnpm_tfidf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtodense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   1844\u001B[0m         \"\"\"\n\u001B[1;32m   1845\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_params\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1846\u001B[0;31m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_documents\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1847\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tfidf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1848\u001B[0m         \u001B[0;31m# X is already a transformed view of raw_documents so\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   1200\u001B[0m         \u001B[0mmax_features\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_features\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1201\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1202\u001B[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001B[0m\u001B[1;32m   1203\u001B[0m                                           self.fixed_vocabulary_)\n\u001B[1;32m   1204\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_count_vocab\u001B[0;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[1;32m   1112\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mraw_documents\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1113\u001B[0m             \u001B[0mfeature_counter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1114\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mfeature\u001B[0m \u001B[0;32min\u001B[0m \u001B[0manalyze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1115\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1116\u001B[0m                     \u001B[0mfeature_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvocabulary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_analyze\u001B[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001B[0m\n\u001B[1;32m    104\u001B[0m             \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpreprocessor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m             \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    107\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mngrams\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstop_words\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Retrieval oracle\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 1, stop_words = 'english')\n",
    "features = tf.fit_transform(raw_documents.values())\n",
    "npm_tfidf = features.todense()\n",
    "\n",
    "# Return all document ids that have cosine similarity with the query larger than a threshold\n",
    "def search_vec_sklearn(query, features, threshold=0.1):\n",
    "    new_features = tf.transform([query])\n",
    "    cosine_similarities = linear_kernel(new_features, features).flatten()\n",
    "    related_docs_indices, cos_sim_sorted = zip(*sorted(enumerate(cosine_similarities), key=itemgetter(1),\n",
    "                                                       reverse=True))\n",
    "    doc_ids = []\n",
    "    for i, cos_sim in enumerate(cos_sim_sorted):\n",
    "        if cos_sim < threshold:\n",
    "            break\n",
    "        doc_ids.append(related_docs_indices[i])\n",
    "    return doc_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# computing the search result\n",
    "def search_vec(query, topk=10):\n",
    "    q = query.split()\n",
    "    query_vector = vectorize(q, vocabulary, idf)\n",
    "    scores = [[cosine_similarity(query_vector, document_vectors[d]), d] for d in range(len(documents))]\n",
    "    scores.sort(key=lambda x: -x[0])\n",
    "    doc_ids = []\n",
    "    for i in range(topk):\n",
    "        doc_ids.append(scores[i][1])\n",
    "    return doc_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
